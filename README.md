# -2022-10-29
文本分类
# 1. 文本分类简介

* 计算机将载有信息的一篇文本映射到预先给定的某一类别或某几类别主题的过程。
* 实现这一过程的算法模型叫做分类器。
* 传统机器学习方法&深度学习文本分类方法

# 2. 文本分类的应用场景

情感分析（SA），话题标记（TL），新闻分类（NC），问答系统（QA），对话行为分类（DAC），自然语言推理（NLD），关系分类（RC），事件预测（EP）。

# 3. 文本分类流程

现在常见的文本分类流程都是基于机器学习或深度学习的。

文本分类系统流程如图所示：

![image](assets/image-20221029093940-hw9a81n.png)

# 4. 浅层学习的具体过程

![image](assets/image-20221027154512-ohoibvo.png)

## 4.1 训练集的获取

* 分别用到两种方法：爬虫技术+页面处理

## 4.2 文本特征工程

### 4.2.1 文本预处理

文本要转化成计算机可以处理的数据结构，需要将文本切分成构成文本的语义单元。

* 英文文本预处理

  * 分割单词+去除标点符号、空格+大小写转换

  * 词根的还原（词干提取）

    computed, computer, computing ---> compute

    词干提取的目的：进一步增加类别与文档中词之间的匹配度。

* 中文文本预处理

  * 分词

    * 基于词典的中文分词方法
    * 基于统计的中文分词方法
    * 基于人工智能技术（理解）的中文分词方法
  * 去停用词

### 4.2.2 文本特征提取（特征选择）

特征提取就是要想办法选出那些最能表现文本含义的词组元素。

向量空间模型文本表示方法的特征提取分为：特征项选择&特征权重计算。

* #TF-IDF模型#

  利用TF和IDF两个参数来表示词语在文本中的重要程度。

  * TF（词频）体现词语在文档内部的重要性。

    $$
    \mathrm{tf}_{\mathrm{ij}}=\frac{\mathrm{n}_{\mathrm{ij}}}{\sum_{\mathrm{k}} \mathrm{n}_{\mathrm{kj}}}
    $$
  * IDF（逆文档频率）体现词语在文档间的重要性。

    $$
    \mathrm{idf}_{\mathrm{i}}=\log \left(\frac{|\mathrm{D}|}{1+\left|\mathrm{D}_{\mathrm{i}}\right|}\right)
    $$
  * 把TF和IDF两个值相乘就可以得到TF-IDF的值。

    $$
   \mathrm{tf} * \operatorname{idf}(\mathrm{i}, \mathrm{j})=\mathrm{tf}_{\mathrm{ij}} * \mathrm{idf}_{\mathrm{i}}=\frac{\mathrm{n}_{\mathrm{ij}}}{\sum_{\mathrm{k}} \mathrm{n}_{\mathrm{kj}}} * \log \left(\frac{|\mathrm{D}|}{1+\left|\mathrm{D}_{\mathrm{i}}\right|}\right)
    $$

  TF-IDF方法的主要思路是一个词在当前类别的重要程度与当前类别内的词频成正比，与所有类别出现的次数成反比。
* 基于卡方检验的特征选择
* 基于词向量的特征提取模型

  * 该模型通常基于大量的文本语料库，通过类似神经网络模型训练，将每个词语映射成一个定维度的向量，维度在几十维到百维之间，每个向量就代表着这个词语，词语的语义和语法相似性和通过向量之间的相似度来判断。
  * #word2vec#

    常用的两个模型：#CBOW模型&amp;skip-gram模型#

### 4.2.3 文本表示

* 文本表示的作用：将非结构化的信息转化为计算机可以理解的结构化信息。
* 文本表示的方法：

  * #词袋模型（BOW）#
  * 向量空间模型（在词向量中给每个词一定的权重）

    互异性&无关性
  * 词嵌入（word embeding）
  * 基于词嵌入的独热编码（one-hot representation）

## 4.3 分类器（分类算法模型）

### 4.3.1 传统机器学习方法（浅层学习模型）

* 基于规则的模型

  * 时间复杂度低、运算速度快
  * 决策树就是一种基于训练学习方法获取分类规则的常见分类模型，它建立对象属性与对象值之间的一种映射。通过构造决策树来对未标注文本进行分类判别。常用的决策树方法包括 CART 算法、ID3、C4.5、CHAID 等。
* 基于概率的模型

  概率模型分类是计算出条件概率模型P(ci | d)，即d属于ci类别的概率，将与文档d条件概率最大的那个类别作为该文档的输出类别。

  * #朴素贝叶斯分类器#

    $$
    P(A \mid B)=\frac{P(B \mid A) P(A)}{P(B)}
    $$

    朴素贝叶斯分类的基本思想是利用词组与类别的联合概率来估计给定文档的类别概率。

    $$
    \mathrm{P}\left(\mathrm{d} \mid \mathrm{c}_{\mathrm{i}}\right)=\Pi_{\mathrm{k}=1}^{\mathrm{n}} \mathrm{P}\left(\mathrm{t}_{\mathrm{k}} \mid \mathrm{c}_{\mathrm{i}}\right)
    $$

    其中，t_k表示含有n项词组的词组表v_i中的一个词组。因此，估计概率P(d | ci)转化为了估计词组表v中的每一个词组在每一个类别下的概率P(tk | ci)。
  * 事件空间的选择

    * 多重伯努利事件空间（布尔独立模型）
    * 多项式事件空间
* 基于几何学的模型

  使用向量空间模型表示文本，文本就被表示为一个多维的向量，那么它就是多维空间的一个点。通过几何学原理构建一个超平面将不属于同一个类别的文本区分开。

  * #SVM#
* 基于统计的模型

  * #k近邻模型（KNN）#

    KNN分类模型的主要思想：通过给定一个未标注文档d，分类系统在训练集中查找与它距离最接近的k篇相邻（相似或相同）标注文档，然后根据这k篇邻近文档的分类标注来确定文档d的类别。

# 5. 深度学习方法

* 浅层学习模式 ---> 深度学习模式
* 与基于浅层学习的方法相比，深度学习方法避免了人工设计规则和特征，并自动提供文本挖掘的语义表示。
* 与浅层模型不同，深度学习通过学习一组直接将特征映射到输出的非线性转换，将特征工程集成到模型拟合过程中。
* 应用深度学习解决大规模文本分类问题最重要的是解决文本表示，再利用CNN/RNN等网络结构自动获取特征表达能力，去掉繁杂的人工特征工程，端到端的解决问题。

## 5.1 基于深度学习的文本分类

DNN文本分类算法分类：

* 基于递归神经网络的方法（ReNN-based methods）
* 基于多层感知机的方法（MLP-based methods）
* 基于循环神经网络的方法（RNN-based methods）

  * 长短期记忆（LSTM）

    解决长序列训练过程中的**梯度消失和梯度爆炸**问题。
* 基于卷积神经网络的方法（CNN-based methods）

  与RNN不同，CNN可以同时将不同核定义的卷积应用于序列的多个块。对于文本分类，需要将文本表示为类似于图像表示的向量，可以从多个角度对文本特征进行过滤。
* 基于注意力机制的方法（Attention-based methods）

  * #HAN#

    HAN包括两个编码器和两个层次的注意层。注意机制让模型对特定的输入给予不同的注意。它先将关键词聚合成句子向量，再将关键句子向量聚合成文本向量。通过这两个层次的注意，可以了解每个单词和句子对分类判断贡献多少，有利于应用和分析。
* 基于Transformer的方法（Transformer-based methods）

  * #BERT模型（预训练的言语表征模型）#
* 基于图神经网络的方法（GNN-based methods）

# 6. 文本分类仍面临的挑战

## 6.1 数据层面

* 零次学习/少量学习
* 外部知识
* 多标签文本分类任务
* 具有许多术语词汇的特殊领域

## 6.2 模型层面

## 6.3 性能评估层面

* 模型的语义鲁棒性
* 模型的可解释性
